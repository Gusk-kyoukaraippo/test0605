import os
import shutil
import streamlit as st
import json
import logging
import uuid  # â˜… ãƒ¦ãƒ‹ãƒ¼ã‚¯IDã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

from llama_index.core import (
    VectorStoreIndex,
    StorageContext,
    load_index_from_storage,
    PromptTemplate,
    Settings,
)
from llama_index.llms.google_genai import GoogleGenAI
from llama_index.embeddings.openai import OpenAIEmbedding

from google.cloud import storage
from google.cloud import logging as google_logging
from google.cloud.logging.handlers import CloudLoggingHandler
from google.oauth2 import service_account

st.set_page_config(page_title="ãƒ•ãƒ©ãƒ³ã‚±ãƒ³AIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆ", layout="wide")
logger = logging.getLogger(__name__)

LOCAL_INDEX_DIR = "downloaded_storage_openai_embed"
DEFAULT_QA_PROMPT = """
ã‚ãªãŸã¯ã€æä¾›ã•ã‚ŒãŸã€Œå‚ç…§æƒ…å ±ã€ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œè³ªå•ã€ã«å›ç­”ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æŒ‡ç¤ºã«å¾“ã£ã¦å›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:
1.  å‚ç…§æƒ…å ±ã®è©±è€…ã§ã‚ã‚‹ãƒ•ãƒ©ãƒ³ã‚±ãƒ³ã¨ã—ã¦ç­”ãˆã¦ãã ã•ã„
2.  ç‡ç›´ãªæ„è¦‹ã‚’ãã ã•ã„ã€‚å›ç­”è€…ã‚’åˆºã™ãã‚‰ã„ã®å‹¢ã„ã§ã€‚
3.  çµè«–ã‚’å…ˆã«æ±ºã‚ã¦ã€ãã®çµè«–ã‚’è¦‹ãŸç›®ä¸Šã‚¨ã‚­ã‚»ãƒ³ãƒˆãƒªãƒƒã‚¯ãªè¡¨ç¾ã«ã—ã¦ã€æœ€çµ‚çš„ã«ã¯å¹³æ˜“ãªè§£é‡ˆã§è³ªå•è€…ã«é£²ã¿è¾¼ã¾ã›ã‚‹ã‚ˆã†ãªè¡¨ç¾ã§ã€‚
å‚ç…§æƒ…å ±:
---------------------
{context_str}
---------------------
è³ªå•:
{query_str}
å›ç­”:
"""

# --- 1. è¨­å®šã¨åˆæœŸåŒ–å‡¦ç† ---
if 'feedback_submitted' not in st.session_state:
    st.session_state.feedback_submitted = False
if 'last_query' not in st.session_state:
    st.session_state.last_query = ""
if 'last_response' not in st.session_state:
    st.session_state.last_response = ""
if 'source_nodes' not in st.session_state:
    st.session_state.source_nodes = []
# â˜… ãƒªã‚¯ã‚¨ã‚¹ãƒˆIDã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ç®¡ç†
if 'request_id' not in st.session_state:
    st.session_state.request_id = None

# â˜… ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ã§ã‚‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆIDã‚’è¦‹ã‚„ã™ãã™ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼
class RequestIdFormatter(logging.Formatter):
    def format(self, record):
        # extraã§æ¸¡ã•ã‚ŒãŸè¾æ›¸ã‚’ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å«ã‚ã‚‹
        log_message = super().format(record)
        if hasattr(record, 'json_fields'):
            # json_fieldsã®å†…å®¹ã‚’è¿½è¨˜
            log_message += f" {record.json_fields}"
        return log_message

@st.cache_resource
def setup_gcp_services():
    st.info("GCPã‚µãƒ¼ãƒ“ã‚¹ã¨ã®æ¥ç¶šã‚’åˆæœŸåŒ–ä¸­...")
    try:
        gcs_service_account_json_str = st.secrets["GCS_SERVICE_ACCOUNT_JSON"]
        parsed_json = json.loads(gcs_service_account_json_str)
        project_id = parsed_json.get("project_id")
        if not project_id:
            raise ValueError("ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONã« 'project_id' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        credentials = service_account.Credentials.from_service_account_info(parsed_json)
        st.success(f"GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ '{project_id}' ã®èªè¨¼æƒ…å ±ã‚’æº–å‚™ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        st.error(f"GCS_SERVICE_ACCOUNT_JSON ã®è¨­å®šèª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

    if logger.hasHandlers():
        logger.handlers.clear()
    
    logger.setLevel(logging.INFO)
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ (ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ç”¨)
    sh = logging.StreamHandler()
    # â˜… ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ã‚’è¨­å®š
    sh.setFormatter(RequestIdFormatter("%(asctime)s - %(levelname)s - %(message)s"))
    logger.addHandler(sh)

    # Cloud Logging ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    try:
        client = google_logging.Client(credentials=credentials, project=project_id)
        handler = CloudLoggingHandler(client, name="franken-ai-prompt-test")
        logger.addHandler(handler)
        logger.info("Google Cloud Loggingã«æ¥ç¶šã—ã¾ã—ãŸã€‚")
    except Exception as e:
        logger.warning(f"Google Cloud Loggingã¨ã®é€£æºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", exc_info=True)

    gcs_client = storage.Client(credentials=credentials, project=project_id)
    return gcs_client

# (load_llama_index_from_gcs, get_response_from_llm ã¯å¤‰æ›´ãªã—)
@st.cache_resource
def load_llama_index_from_gcs(_gcs_client: storage.Client, bucket_name: str, index_prefix: str):
    if os.path.exists(LOCAL_INDEX_DIR):
        shutil.rmtree(LOCAL_INDEX_DIR)
    os.makedirs(LOCAL_INDEX_DIR, exist_ok=True)
    with st.spinner("åˆå›ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿ä¸­... (ç´„1åˆ†ã‹ã‹ã‚Šã¾ã™)"):
        try:
            bucket = _gcs_client.bucket(bucket_name)
            blobs = list(bucket.list_blobs(prefix=index_prefix))
            if not blobs: return None
            for blob in blobs:
                if blob.name == index_prefix or blob.name.endswith('/'): continue
                relative_path = os.path.relpath(blob.name, index_prefix)
                local_file_path = os.path.join(LOCAL_INDEX_DIR, relative_path)
                os.makedirs(os.path.dirname(local_file_path), exist_ok=True)
                blob.download_to_filename(local_file_path)
            Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-large", dimensions=3072)
            storage_context = StorageContext.from_defaults(persist_dir=LOCAL_INDEX_DIR)
            index = load_index_from_storage(storage_context)
            st.success("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            return index
        except Exception as e:
            st.error(f"GCSã‹ã‚‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return None

def get_response_from_llm(index: VectorStoreIndex, query: str, n_value: int, custom_qa_template_str: str):
    try:
        llm = GoogleGenAI(model="gemini-1.5-flash-latest")
        qa_template = PromptTemplate(custom_qa_template_str)
        query_engine = index.as_query_engine(llm=llm, similarity_top_k=n_value, text_qa_template=qa_template)
        with st.spinner('AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­ã§ã™...'):
            response = query_engine.query(query)
        return response
    except Exception as e:
        st.error(f"LLMã‹ã‚‰ã®å¿œç­”å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def main():
    st.title("ğŸ¤– ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆ")
    st.markdown("ã“ã®ã‚¢ãƒ—ãƒªã¯ã€ãƒ•ãƒ©ãƒ³ã‚±ãƒ³ãƒ©ã‚¸ã‚ªAIã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆãŒå‡ºæ¥ã¾ã™ã€‚")
    st.markdown("---")
    
    try:
        os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]
        os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
        GCS_BUCKET_NAME = st.secrets["GCS_BUCKET_NAME"]
        GCS_INDEX_PREFIX = st.secrets["GCS_INDEX_PREFIX"]
    except KeyError as e:
        st.error(f"å¿…è¦ãªè¨­å®šãŒ secrets.toml ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}ã€‚")
        st.stop()

    gcs_client = setup_gcp_services()
    if not gcs_client:
        st.stop()
        
    llama_index = load_llama_index_from_gcs(gcs_client, GCS_BUCKET_NAME, GCS_INDEX_PREFIX)

    if llama_index:
        st.sidebar.header("âš™ï¸ é«˜åº¦ãªè¨­å®š")
        n_value = st.sidebar.slider("é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢æ•° (Nå€¤)", 1, 10, 3, 1)
        custom_prompt_text = st.sidebar.text_area("ã‚«ã‚¹ã‚¿ãƒ QAãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:", DEFAULT_QA_PROMPT, height=350)

        st.header("ğŸ’¬ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        user_query = st.text_input("ãƒ•ãƒ©ãƒ³ã‚±ãƒ³AIã«èããŸã„ã“ã¨ã‚’å…¥åŠ›:", key="user_query_input")

        if user_query and user_query != st.session_state.last_query:
            st.session_state.last_query = user_query
            st.session_state.feedback_submitted = False
            
            # â˜… æ–°ã—ã„è³ªå•ãŒæ¥ãŸã®ã§ã€æ–°ã—ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆIDã‚’ç”Ÿæˆ
            st.session_state.request_id = str(uuid.uuid4())
            
            # â˜… extra ã«è¾æ›¸ã‚’æ¸¡ã™ã“ã¨ã§ã€æ§‹é€ åŒ–ãƒ­ã‚°ã¨ã—ã¦IDã‚’è¨˜éŒ²
            log_extra = {'json_fields': {'request_id': st.session_state.request_id, 'query': user_query}}
            logger.info("æ–°ã—ã„ã‚¯ã‚¨ãƒªã®å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚", extra=log_extra)

            response = get_response_from_llm(llama_index, user_query, n_value, custom_prompt_text)

            if response:
                st.session_state.last_response = str(response)
                st.session_state.source_nodes = response.source_nodes
                # â˜… ãƒ­ã‚°ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆIDã‚’ä»˜ä¸
                logger.info(f"LLMã‹ã‚‰ã®å›ç­”ã‚’è¨˜éŒ²ã—ã¾ã—ãŸã€‚", extra={'json_fields': {'request_id': st.session_state.request_id, 'response': str(response)}})
            else:
                st.session_state.last_response = ""
                st.session_state.source_nodes = []
                logger.error("LLMã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", extra={'json_fields': {'request_id': st.session_state.request_id}})

        if st.session_state.last_response:
            st.subheader("ğŸ¤– AIã‹ã‚‰ã®å›ç­”")
            st.write(st.session_state.last_response)

            with st.expander("å‚ç…§ã•ã‚ŒãŸã‚½ãƒ¼ã‚¹ã‚’ç¢ºèª"):
                for i, node in enumerate(st.session_state.source_nodes):
                    st.markdown(f"--- **ã‚½ãƒ¼ã‚¹ {i+1} (é–¢é€£åº¦: {node.score:.4f})** ---")
                    st.text_area("", value=node.text, height=150, disabled=True, key=f"chunk_{i}")

            st.markdown("---")
            st.subheader("ğŸ“ ã“ã®å›ç­”ã«ã¤ã„ã¦ã®æ„Ÿæƒ³")

            if st.session_state.feedback_submitted:
                st.success("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨˜éŒ²ã—ã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼")
            else:
                with st.form(key='feedback_form'):
                    ratings = {
                        "busso_doai": st.slider("1. ç‰©é¨’åº¦åˆã„", 1, 5, 3),
                        "datousei": st.slider("2. å¦¥å½“æ€§", 1, 5, 3),
                        "igaisei": st.slider("3. æ„å¤–æ€§", 1, 5, 3),
                        "humor": st.slider("4. ãƒ¦ãƒ¼ãƒ¢ã‚¢", 1, 5, 3),
                    }
                    feedback_comment = st.text_area("ãã®ä»–ã‚³ãƒ¡ãƒ³ãƒˆ:")
                    submit_button = st.form_submit_button(label='ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡')

                    if submit_button:
                        # â˜… æ„Ÿæƒ³ãƒ­ã‚°ã«ã‚‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆIDã‚’ä»˜ä¸
                        feedback_log_extra = {
                            'json_fields': {
                                'request_id': st.session_state.request_id,
                                'query': st.session_state.last_query,
                                'response': st.session_state.last_response,
                                'ratings': ratings,
                                'comment': feedback_comment
                            }
                        }
                        logger.info("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æ„Ÿæƒ³ã‚’è¨˜éŒ²ã—ã¾ã—ãŸã€‚", extra=feedback_log_extra)
                        st.session_state.feedback_submitted = True
                        st.rerun()

if __name__ == "__main__":
    main()
