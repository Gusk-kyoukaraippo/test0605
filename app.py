import os
import streamlit as st
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, StorageContext, load_index_from_storage, PromptTemplate
from llama_index.llms.google_genai import GoogleGenAI
from google.cloud import storage
import json
import shutil # ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ“ä½œç”¨

# --- 1. Gemini APIã‚­ãƒ¼ã®è¨­å®š ---
try:
    os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]
except KeyError:
    st.error("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚'.streamlit/secrets.toml' ãƒ•ã‚¡ã‚¤ãƒ«ã« GOOGLE_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- 2. GCSè¨­å®šã¨èªè¨¼ ---
try:
    GCS_BUCKET_NAME = st.secrets["GCS_BUCKET_NAME"]
    GCS_INDEX_PREFIX = st.secrets["GCS_INDEX_PREFIX"] # ä¾‹: "my_rag_index/"
    
    # GCSã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã—ã€ç’°å¢ƒå¤‰æ•°ã«è¨­å®š
    gcs_service_account_json_str = st.secrets["GCS_SERVICE_ACCOUNT_JSON"]
    # æ”¹è¡Œã‚³ãƒ¼ãƒ‰ã®ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚’è§£é™¤
    gcs_service_account_json_str = gcs_service_account_json_str.replace('\\n', '\n')
    
    # Streamlitã®ãƒ†ãƒ³ãƒãƒ©ãƒªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ã‚’ä¿å­˜
    # ã“ã‚Œã¯ãƒ‡ãƒ—ãƒ­ã‚¤ç’°å¢ƒã§ã®ã¿å¿…è¦ã§ã€ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ™‚ã¯gcloud CLIèªè¨¼ã‚„ç’°å¢ƒå¤‰æ•°ã§å¯¾å¿œå¯èƒ½
    temp_gcs_key_path = os.path.join("/tmp", "gcs_key.json")
    with open(temp_gcs_key_path, "w") as f:
        f.write(gcs_service_account_json_str)
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = temp_gcs_key_path

except KeyError as e:
    st.error(f"GCSè¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚'.streamlit/secrets.toml' ãƒ•ã‚¡ã‚¤ãƒ«ã« {e} ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()


# ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
LOCAL_INDEX_DIR = "downloaded_storage" # GitHubã«ã¯ä¸ŠãŒã‚‰ãªã„ã®ã§ã“ã®ã¾ã¾ã§OK

# â˜…ã‚«ã‚¹ã‚¿ãƒ QAãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å®šç¾©ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰
DEFAULT_QA_PROMPT = """
ã‚ãªãŸã¯ã€æä¾›ã•ã‚ŒãŸã€Œå‚ç…§æƒ…å ±ã€ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œè³ªå•ã€ã«æ˜ç¢ºã‹ã¤ç°¡æ½”ã«å›ç­”ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æŒ‡ç¤ºã«å¾“ã£ã¦å›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:

1.  ã€Œå‚ç…§æƒ…å ±ã€ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œè³ªå•ã€ã«ã€Œæœ€çµ‚å›ç­”ã€ã‚’1ï½2æ–‡ã§ä½œã£ã¦ãã ã•ã„
2.  ã€Œæœ€çµ‚å›ç­”ã€ã¨ã€Œè³ªå•ã€ã‚’çµã¶èª¬æ˜ã‚’ã€Œå‚ç…§æƒ…å ±ã€ã‚’å‚è€ƒã«ã—ã¤ã¤ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã§ä½œæˆã—ã¦ãã ã•ã„

å‚ç…§æƒ…å ±:
---------------------
{context_str}
---------------------

è³ªå•:
{query_str}

å›ç­”:
"""

@st.cache_resource
def load_llama_index_from_gcs():
    """
    GCSã‹ã‚‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ãã‚Œã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
    """
    # æ—¢å­˜ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªã‚¢ (åˆå›ãƒ­ãƒ¼ãƒ‰æ™‚ã®ã¿å¿…è¦)
    if os.path.exists(LOCAL_INDEX_DIR):
        st.write(f"æ—¢å­˜ã®ãƒ­ãƒ¼ã‚«ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{LOCAL_INDEX_DIR}' ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™...")
        shutil.rmtree(LOCAL_INDEX_DIR) 
    os.makedirs(LOCAL_INDEX_DIR, exist_ok=True) # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ

    st.info(f"GCSãƒã‚±ãƒƒãƒˆ '{GCS_BUCKET_NAME}' ã‹ã‚‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­... (ãƒ‘ã‚¹: '{GCS_INDEX_PREFIX}')")
    
    try:
        # GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– (èªè¨¼ã¯ç’°å¢ƒå¤‰æ•° GOOGLE_APPLICATION_CREDENTIALS çµŒç”±)
        client = storage.Client()
        bucket = client.bucket(GCS_BUCKET_NAME)

        # æŒ‡å®šã•ã‚ŒãŸãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹å†…ã®ã™ã¹ã¦ã®ãƒ–ãƒ­ãƒ–ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—
        blobs = bucket.list_blobs(prefix=GCS_INDEX_PREFIX)
        
        download_count = 0
        for blob in blobs:
            # GCSã®ãƒ‘ã‚¹ã‹ã‚‰ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
            # ä¾‹: my_rag_index/docstore.json -> downloaded_storage/docstore.json
            relative_path = os.path.relpath(blob.name, GCS_INDEX_PREFIX)
            local_file_path = os.path.join(LOCAL_INDEX_DIR, relative_path)
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
            os.makedirs(os.path.dirname(local_file_path), exist_ok=True)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            blob.download_to_filename(local_file_path)
            # st.write(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿: {blob.name} -> {local_file_path}") # ãƒ‡ãƒãƒƒã‚°ç”¨
            download_count += 1
        
        if download_count == 0:
            st.warning(f"GCSãƒã‚±ãƒƒãƒˆ '{GCS_BUCKET_NAME}' ã® '{GCS_INDEX_PREFIX}' ãƒ‘ã‚¹ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‘ã‚¹ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return None

        st.success(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ« {download_count} å€‹ãŒGCSã‹ã‚‰æ­£å¸¸ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸã€‚")

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰
        storage_context = StorageContext.from_defaults(persist_dir=LOCAL_INDEX_DIR)
        index = load_index_from_storage(storage_context)
        st.success("LlamaIndexãŒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ­£å¸¸ã«ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        return index
    except Exception as e:
        st.error(f"GCSã‹ã‚‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.info("GCSãƒã‚±ãƒƒãƒˆåã€ãƒ‘ã‚¹ã€ã¾ãŸã¯èªè¨¼æƒ…å ±ï¼ˆStreamlit Secretsã® GCS_SERVICE_ACCOUNT_JSONï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return None

def get_response_from_llm(index, query: str, n_value: int, custom_qa_template_str: str):
    """
    æŒ‡å®šã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€ã‚¯ã‚¨ãƒªã€Nå€¤ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦LLMã‹ã‚‰å¿œç­”ã‚’å–å¾—ã—ã¾ã™ã€‚
    """
    llm = GoogleGenAI(model="gemini-2.5-flash-preview-05-20") 
    qa_template = PromptTemplate(custom_qa_template_str)

    query_engine = index.as_query_engine(
        llm=llm,
        similarity_top_k=n_value,
        text_qa_template=qa_template
    ) 

    st.info(f"ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œä¸­: '{query}'")
    with st.spinner('AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­ã§ã™...'):
        response = query_engine.query(query)
    return response

# --- Streamlit UIã®æ§‹ç¯‰ ---
st.set_page_config(page_title="RAGãƒ™ãƒ¼ã‚¹QAã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒª (GCSå¯¾å¿œ)", layout="wide")
st.title("ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆQAãƒœãƒƒãƒˆ (GCSé€£æº)")

st.markdown("""
ã“ã®ã‚¢ãƒ—ãƒªã¯ã€Google Cloud Storage (GCS) ã«ä¿å­˜ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åŸºã¥ã„ã¦è³ªå•ã«å›ç­”ã—ã¾ã™ã€‚
å·¦å´ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„é–¢é€£åº¦ (`N` å€¤) ã‚’èª¿æ•´ã—ã¦ã€AIã®å¿œç­”ã‚’è©¦ã™ã“ã¨ãŒã§ãã¾ã™ã€‚
---
""")

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ­ãƒ¼ãƒ‰
# GCSã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°ã‚’å‘¼ã³å‡ºã™
llama_index = load_llama_index_from_gcs()

if llama_index:
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã®è¨­å®š
    st.sidebar.header("âš™ï¸ è¨­å®š")

    # Nå€¤ã®èª¿æ•´ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
    n_value = st.sidebar.slider(
        "é¡ä¼¼åº¦ãƒˆãƒƒãƒ—K (Nå€¤)", 
        min_value=1, 
        max_value=10, 
        value=5, 
        step=1,
        help="å›ç­”ç”Ÿæˆã®ãŸã‚ã«å–å¾—ã™ã‚‹æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ£ãƒ³ã‚¯ã®æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚"
    )
    st.sidebar.info(f"ä¸Šä½ **{n_value}** å€‹ã®é–¢é€£æ€§ã®é«˜ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’ä½¿ç”¨ã—ã¦å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª¿æ•´ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢
    st.sidebar.subheader("ğŸ“ ã‚«ã‚¹ã‚¿ãƒ QAãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    custom_prompt_text = st.sidebar.text_area(
        "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç·¨é›†ã—ã¦ãã ã•ã„ (context_str ã¨ query_str ã¯å¿…é ˆã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã§ã™)",
        DEFAULT_QA_PROMPT,
        height=400,
        help="AIã«æŒ‡ç¤ºã‚’ä¸ãˆã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™ã€‚`{context_str}` ã¨ `{query_str}` ã¯å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚"
    )

    st.sidebar.markdown("---")
    st.sidebar.write("Â© 2024 LlamaIndex Streamlit Demo")

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒªã‚¢
    st.header("è³ªå•ã‚’ã—ã¦ãã ã•ã„")
    user_query = st.text_input("ã“ã“ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ä¾‹: ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§èª¬æ˜ã•ã‚Œã¦ã„ã‚‹ä¸»è¦ãªã‚³ãƒ³ã‚»ãƒ—ãƒˆã¯ä½•ã§ã™ã‹ï¼Ÿ")

    if user_query:
        if "context_str" not in custom_prompt_text or "query_str" not in custom_prompt_text:
            st.warning("ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã¯ `{context_str}` ã¨ `{query_str}` ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            st.info(f"è³ªå•: **{user_query}**")
            response = get_response_from_llm(llama_index, user_query, n_value, custom_prompt_text)
            
            st.subheader("ğŸ¤– å›ç­”")
            st.write(str(response))

            # è©³ç´°æƒ…å ±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            with st.expander("è©³ç´°æƒ…å ±ã‚’è¦‹ã‚‹"):
                st.write("**ä½¿ç”¨ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:**")
                st.code(custom_prompt_text, language='text')
                st.write(f"**ä½¿ç”¨ã•ã‚ŒãŸNå€¤:** {n_value}")
                if hasattr(response, 'source_nodes'):
                    st.write("**å‚ç…§ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒãƒ£ãƒ³ã‚¯:**")
                    for i, node in enumerate(response.source_nodes):
                        st.write(f"--- ãƒãƒ£ãƒ³ã‚¯ {i+1} ---")
                        st.text(node.text)
                        if node.metadata:
                            st.json(node.metadata)
                else:
                    st.info("ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

else:
    st.warning("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€è³ªå•ã«å›ç­”ã§ãã¾ã›ã‚“ã€‚ä¸Šè¨˜ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")