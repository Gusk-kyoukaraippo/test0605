import os
import shutil
import streamlit as st
import json
import tempfile
import numpy as np # ã“ã®è¡Œã¯ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã‚ˆã†ã§ã™ãŒã€å…ƒã®ã‚³ãƒ¼ãƒ‰ã«ã‚ã£ãŸã®ã§æ®‹ã—ã¾ã™ã€‚
from llama_index.core import (
    VectorStoreIndex,
    StorageContext,
    load_index_from_storage,
    PromptTemplate,
    Settings,
)
from llama_index.llms.google_genai import GoogleGenAI
# OpenAIEmbedding ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã«ã€GoogleGenAIEmbedding ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã¾ãŸã¯å‰Šé™¤ã—ã€OpenAIEmbedding ã‚’è¿½åŠ ã—ã¾ã™ã€‚
# from llama_index.embeddings.google_genai import GoogleGenAIEmbedding 
from llama_index.embeddings.openai import OpenAIEmbedding # â˜…ã“ã“ã‚’OpenAIEmbeddingã«å¤‰æ›´

from google.cloud import storage

# --- ãƒšãƒ¼ã‚¸è¨­å®š (æœ€åˆã«ä¸€åº¦ã ã‘å‘¼ã³å‡ºã™) ---
st.set_page_config(page_title="ãƒ•ãƒ©ãƒ³ã‚±ãƒ³AIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆ", layout="wide")

# --- ãƒ­ã‚®ãƒ³ã‚°è¨­å®š ---
LOG_FILE = "app.log"
# æ—¥æœ¬èªã‚’å«ã‚€ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ­£ã—ããƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ã™ã‚‹ãŸã‚ã« encoding='utf-8' ã‚’æŒ‡å®š
# Streamlitã®å†å®Ÿè¡Œæ™‚ã«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒé‡è¤‡ã—ã¦è¿½åŠ ã•ã‚Œã‚‹ã®ã‚’é˜²ããŸã‚ã€ãƒ­ã‚¬ãƒ¼ã®æ—¢å­˜ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢
logger = logging.getLogger(__name__)
if not logger.handlers: # ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒã¾ã è¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿è¨­å®š
    logger.setLevel(logging.INFO)
    formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    fh = logging.FileHandler(LOG_FILE, encoding='utf-8')
    fh.setFormatter(formatter)
    logger.addHandler(fh)
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ (ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›)
    sh = logging.StreamHandler()
    sh.setFormatter(formatter)
    logger.addHandler(sh)


# --- å®šæ•°å®šç¾© ---
LOCAL_INDEX_DIR = "downloaded_storage_openai_embed" # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‚’å¤‰æ›´ã—ã€åŒºåˆ¥ã—ã¾ã™
DEFAULT_QA_PROMPT = """
ã‚ãªãŸã¯ã€æä¾›ã•ã‚ŒãŸã€Œå‚ç…§æƒ…å ±ã€ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œè³ªå•ã€ã«å›ç­”ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æŒ‡ç¤ºã«å¾“ã£ã¦å›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:

1.  å‚ç…§æƒ…å ±ã®è©±è€…ã§ã‚ã‚‹ãƒ•ãƒ©ãƒ³ã‚±ãƒ³ã¨ã—ã¦ç­”ãˆã¦ãã ã•ã„
2.  ç‡ç›´ãªæ„è¦‹ã‚’ãã ã•ã„ã€‚å›ç­”è€…ã‚’åˆºã™ãã‚‰ã„ã®å‹¢ã„ã§ã€‚
3.  çµè«–ã‚’å…ˆã«æ±ºã‚ã¦ã€ãã®çµè«–ã‚’è¦‹ãŸç›®ä¸Šã‚¨ã‚­ã‚»ãƒ³ãƒˆãƒªãƒƒã‚¯ãªè¡¨ç¾ã«ã—ã¦ã€æœ€çµ‚çš„ã«ã¯å¹³æ˜“ãªè§£é‡ˆã§è³ªå•è€…ã«é£²ã¿è¾¼ã¾ã›ã‚‹ã‚ˆã†ãªè¡¨ç¾ã§ã€‚

å‚ç…§æƒ…å ±:
---------------------
{context_str}
---------------------

è³ªå•:
{query_str}

å›ç­”:
"""

# --- 1. APIã‚­ãƒ¼ã¨GCSèªè¨¼æƒ…å ±ã®è¨­å®š ---
temp_gcs_key_path = None
try:
    # Streamlit secretsã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
    # GOOGLE_API_KEYãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª (Gemini LLMç”¨)
    if "GOOGLE_API_KEY" not in st.secrets:
        raise KeyError("GOOGLE_API_KEY")
    os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]

    # â˜…OpenAI APIã‚­ãƒ¼ã®è¿½åŠ 
    if "OPENAI_API_KEY" not in st.secrets:
        raise KeyError("OPENAI_API_KEY")
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]


    # GCSé–¢é€£ã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    if "GCS_BUCKET_NAME" not in st.secrets:
        raise KeyError("GCS_BUCKET_NAME")
    GCS_BUCKET_NAME = st.secrets["GCS_BUCKET_NAME"]

    if "GCS_INDEX_PREFIX" not in st.secrets:
        raise KeyError("GCS_INDEX_PREFIX")
    GCS_INDEX_PREFIX = st.secrets["GCS_INDEX_PREFIX"]

    if "GCS_SERVICE_ACCOUNT_JSON" not in st.secrets:
        raise KeyError("GCS_SERVICE_ACCOUNT_JSON")
    gcs_service_account_json_str = st.secrets["GCS_SERVICE_ACCOUNT_JSON"]

    # GCSã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    try:
        parsed_json = json.loads(gcs_service_account_json_str)
        clean_json_str = json.dumps(parsed_json)
    except json.JSONDecodeError as e:
        st.error(f"Streamlit secretsã®'GCS_SERVICE_ACCOUNT_JSON'ãŒä¸æ­£ãªJSONå½¢å¼ã§ã™: {e}")
        st.info(
            "secrets.tomlã®GCPã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ãŒæ­£ã—ã„JSONå½¢å¼ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            "ç‰¹ã«ã€ä¸‰é‡å¼•ç”¨ç¬¦(`\"\"\"`)ã§å›²ã‚€ã¨æ”¹è¡Œã‚„ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã®å•é¡ŒãŒèµ·ãã«ãããªã‚Šã¾ã™ã€‚"
        )
        st.stop()

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«èªè¨¼æƒ…å ±ã‚’æ›¸ãå‡ºã—ã€ç’°å¢ƒå¤‰æ•°ã«ãƒ‘ã‚¹ã‚’è¨­å®š
    with tempfile.NamedTemporaryFile(mode="w", delete=False, suffix=".json", encoding="utf-8") as tmp_file:
        tmp_file.write(clean_json_str)
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = tmp_file.name # temp_gcs_key_path ã¯ä¸è¦ã«ãªã£ãŸãŸã‚ç›´æ¥ä»£å…¥
    temp_gcs_key_path = tmp_file.name # å¾Œã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹ãŸã‚ã«ãƒ‘ã‚¹ã‚’ä¿æŒ

except KeyError as e:
    st.error(
        f"å¿…è¦ãªè¨­å®šãŒ secrets.toml ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}ã€‚"
        "GOOGLE_API_KEY, OPENAI_API_KEY, GCS_BUCKET_NAME, GCS_INDEX_PREFIX, GCS_SERVICE_ACCOUNT_JSON ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
    )
    st.stop()
except Exception as e:
    st.error(f"è¨­å®šã®èª­ã¿è¾¼ã¿ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    st.exception(e)
    st.stop()


# --- 2. LlamaIndexé–¢é€£ã®é–¢æ•° ---
@st.cache_resource
def load_llama_index_from_gcs():
    """
    Google Cloud Storage (GCS) ã‹ã‚‰LlamaIndexã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
    ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¾ã™ã€‚
    """
    if os.path.exists(LOCAL_INDEX_DIR):
        shutil.rmtree(LOCAL_INDEX_DIR)
    os.makedirs(LOCAL_INDEX_DIR, exist_ok=True)

    # åˆå›èª­ã¿è¾¼ã¿æ™‚é–“ã®æç¤º
    with st.spinner("åˆå›èª­ã¿è¾¼ã¿ä¸­... (ç´„1åˆ†ã‹ã‹ã‚Šã¾ã™)"):
        st.info(f"GCSãƒã‚±ãƒƒãƒˆ '{GCS_BUCKET_NAME}' ã‹ã‚‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")

        try:
            client = storage.Client()
            bucket = client.bucket(GCS_BUCKET_NAME)
            blobs = list(bucket.list_blobs(prefix=GCS_INDEX_PREFIX))

            if not blobs or all(blob.name == GCS_INDEX_PREFIX and blob.size == 0 for blob in blobs):
                st.warning(f"GCSãƒã‚±ãƒƒãƒˆ '{GCS_BUCKET_NAME}' ã® '{GCS_INDEX_PREFIX}' ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                return None

            download_count = 0
            for blob in blobs:
                if blob.name == GCS_INDEX_PREFIX or blob.name.endswith('/'):
                    continue
                relative_path = os.path.relpath(blob.name, GCS_INDEX_PREFIX)
                local_file_path = os.path.join(LOCAL_INDEX_DIR, relative_path)
                os.makedirs(os.path.dirname(local_file_path), exist_ok=True)
                blob.download_to_filename(local_file_path)
                download_count += 1

            if download_count == 0:
                st.warning(f"GCSã® '{GCS_INDEX_PREFIX}' ãƒ‘ã‚¹ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return None

            st.success(f"{download_count} å€‹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")

            # â˜…åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šã‚’OpenAI Embeddingã«å¤‰æ›´
            Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-large", dimensions=3072)
            st.info(f"åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«: **{Settings.embed_model.model_name}** (æ¬¡å…ƒ: **{Settings.embed_model.dimensions}**) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")


            # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ãŒæ©Ÿèƒ½ã™ã‚‹ã‹ãƒ†ã‚¹ãƒˆ
            try:
                test_embedding = Settings.embed_model.get_text_embedding("ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆæ–‡å­—åˆ—ã§ã™ã€‚")
                if not isinstance(test_embedding, list) or len(test_embedding) == 0:
                    st.error("åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ãŒæœ‰åŠ¹ãªåŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚APIã‚­ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    return None

                expected_dimension = 3072 # â˜…æœŸå¾…ã•ã‚Œã‚‹æ¬¡å…ƒæ•°ã‚’3072ã«å¤‰æ›´
                if len(test_embedding) != expected_dimension:
                    st.error(
                        f"åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã•ã‚Œã‚‹ {expected_dimension} æ¬¡å…ƒã§ã¯ãªãã€"
                        f"{len(test_embedding)} æ¬¡å…ƒã‚’è¿”ã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«è¨­å®šã¾ãŸã¯APIã®åˆ¶é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                    )
                    st.info(
                        "`text-embedding-3-large` ãƒ¢ãƒ‡ãƒ«ãŒå®Ÿéš›ã«3072æ¬¡å…ƒã®å‡ºåŠ›ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã‹ã€"
                        "ã¾ãŸã¯ãã®æ¬¡å…ƒã§åˆ©ç”¨å¯èƒ½ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                    )
                    return None
                st.success("åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚")
            except Exception as e:
                st.error(f"åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.info("APIã‚­ãƒ¼ ('OPENAI_API_KEY') ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ã€OpenAI Embedding APIã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒè¨±å¯ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                return None

            # ãƒ­ãƒ¼ã‚«ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰
            storage_context = StorageContext.from_defaults(persist_dir=LOCAL_INDEX_DIR)
            index = load_index_from_storage(storage_context)
            st.success("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚è³ªå•ã‚’å…¥åŠ›ã§ãã¾ã™ã€‚")
            return index

        except Exception as e:
            st.error(f"GCSã‹ã‚‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.exception(e)
            st.info(
                "ä»¥ä¸‹ã®ç‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:\n"
                f"- GCSãƒã‚±ãƒƒãƒˆå ('{GCS_BUCKET_NAME}') ã¨ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ ('{GCS_INDEX_PREFIX}') ãŒæ­£ã—ã„ã‹ã€‚\n"
                "- 'GCS_SERVICE_ACCOUNT_JSON' ãŒæ­£ã—ãã€é©åˆ‡ãªæ¨©é™ã‚’æŒã£ã¦ã„ã‚‹ã‹ã€‚\n"
                "- ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒå®‰å®šã—ã¦ã„ã‚‹ã‹ã€‚"
            )
            return None
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ (å¿µã®ãŸã‚ã€Streamlitã‚¢ãƒ—ãƒªã®å®Ÿè¡ŒãŒçµ‚äº†ã™ã‚‹ã¾ã§æ®‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™)
            if temp_gcs_key_path and os.path.exists(temp_gcs_key_path):
                os.remove(temp_gcs_key_path)

def get_response_from_llm(index: VectorStoreIndex, query: str, n_value: int, custom_qa_template_str: str):
    """
    LLMã‚’ä½¿ç”¨ã—ã¦ã€LlamaIndexã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    """
    try:
        # LLMã¯Geminiã®ã¾ã¾å¤‰æ›´ãªã—
        llm = GoogleGenAI(model="gemini-2.5-flash-preview-05-20") 
        qa_template = PromptTemplate(custom_qa_template_str)
        query_engine = index.as_query_engine(
            llm=llm,
            similarity_top_k=n_value,
            text_qa_template=qa_template
        )
        with st.spinner('AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­ã§ã™...'):
            response = query_engine.query(query)
        return response
    except Exception as e:
        st.error(f"LLMã‹ã‚‰ã®å¿œç­”å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.exception(e)
        st.info("Gemini APIã‚­ãƒ¼ãŒæœ‰åŠ¹ã‹ã€é¸æŠã—ãŸLLMãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€LlamaIndexãŒé©åˆ‡ã«åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã§ãã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return None

# --- 3. Streamlit UIã®æ§‹ç¯‰ ---
def main():
    """
    Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³UIã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚
    """
    st.title("ğŸ¤– ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆ")
    st.markdown("""
                ##åˆå›èª­ã¿è¾¼ã¿ã«3åˆ†ã»ã©ã‹ã‹ã‚Šã¾ã™\n
    ã“ã®ã‚¢ãƒ—ãƒªã¯ã€ãƒ•ãƒ©ãƒ³ã‚±ãƒ³ãƒ©ã‚¸ã‚ªAIã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆãŒå‡ºæ¥ã¾ã™ã€‚\n
    notebookLMã¨é•ã„ã€å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®šã§è³ªå•å¿œç­”ã®æŒ™å‹•ã‚’èª¿æ•´ã§ãã¾ã™ã€‚\n
    è¨­å®šé …ç›®ã¯3ã¤ã‚ã‚Šã¾ã™ã€‚\n
    1:å·¦ä¸Šæ®µã¯ã€å‚ç…§æƒ…å ±ã‚’ä½•ã‹æ‰€å…¥ã‚Œè¾¼ã‚€ã‹è¨­å®šã§ãã¾ã™ã€‚(1ã‚«æ‰€ã§ãƒ©ã‚¸ã‚ªç´„3åˆ†)\n
    2:å·¦ã—ãŸæ®µã§ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®šã§ãã¾ã™ã€‚\n
    3:å·¦ã®è¨­å®šå¾Œã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«è¨˜å…¥ã—ã¦ã‚¨ãƒ³ã‚¿ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„
    """)
    st.markdown("---")

    llama_index = load_llama_index_from_gcs()

    if llama_index:
        st.sidebar.header("âš™ï¸ é«˜åº¦ãªè¨­å®š")
        n_value = st.sidebar.slider(
            "é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢æ•° (Nå€¤)", 1, 10, 3, 1,
            help="å›ç­”ç”Ÿæˆã®éš›ã«å‚ç…§ã™ã‚‹ã€é–¢é€£æ€§ã®é«˜ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ•°ã‚’æŒ‡å®šã—ã¾ã™ã€‚ç´„3åˆ†ã®å†…å®¹ãŒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ1ã¤ã«ç›¸å½“ã—ã¾ã™"
        )
        st.sidebar.info(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ1ã¤ãŒç´„3åˆ†ã®å†…å®¹ã«ç›¸å½“ã—ã¾ã™ã€‚ç¾åœ¨ã€ä¸Šä½ **{n_value}** å€‹ã®é–¢é€£å†…å®¹ã‚’ä½¿ç”¨ã—ã¦å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

        st.sidebar.subheader("ğŸ“ ã‚«ã‚¹ã‚¿ãƒ QAãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
        custom_prompt_text = st.sidebar.text_area(
            "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç·¨é›†ã—ã¦ãã ã•ã„:",
            DEFAULT_QA_PROMPT, height=350,
            help="AIã¸ã®æŒ‡ç¤ºã§ã™ã€‚**`{context_str}` (å‚ç…§æƒ…å ±)** ã¨ **`{query_str}` (ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•)** ã¯å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚ã“ã‚Œã‚‰ãŒå«ã¾ã‚Œã¦ã„ãªã„ã¨ã€AIã¯é©åˆ‡ã«å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚"
        )
        st.sidebar.markdown("---")
        st.sidebar.caption("Â© 2024 RAG Demo")

        st.header("ğŸ’¬ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        user_query = st.text_input(
            "ãƒ•ãƒ©ãƒ³ã‚±ãƒ³AIã«èããŸã„ã“ã¨ã‚’ã“ã“ã«å…¥åŠ›ã—ã¦ãã ã•ã„:",
            placeholder="ä¾‹: ä»Šå¾Œã®ã‚­ãƒ£ãƒªã‚¢ã¯ã©ã†ã—ãŸã‚‰ã„ã„ã§ã—ã‚‡ã†ã‹ï¼Ÿ",
            help="è³ªå•ã‚’å…¥åŠ›ã—ã¦Enterã‚­ãƒ¼ã‚’æŠ¼ã™ã‹ã€å°‘ã—å¾…ã¤ã¨å›ç­”ãŒç”Ÿæˆã•ã‚Œã¾ã™ã€‚"
        )

        if user_query:
            if "{context_str}" not in custom_prompt_text or "{query_str}" not in custom_prompt_text:
                st.warning("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã¯`{context_str}`ã¨`{query_str}`ã®ä¸¡æ–¹ã‚’å«ã‚ã¦ãã ã•ã„ã€‚ã“ã‚Œã‚‰ã¯AIãŒå‚ç…§æƒ…å ±ã¨è³ªå•ã‚’èªè­˜ã™ã‚‹ãŸã‚ã«å¿…é ˆã§ã™ã€‚")
            else:
                response = get_response_from_llm(llama_index, user_query, n_value, custom_prompt_text)
                if response:
                    st.subheader("ğŸ¤– AIã‹ã‚‰ã®å›ç­”")
                    st.write(str(response))
                    
                    # å‚ç…§ã‚½ãƒ¼ã‚¹ã®è¡¨ç¤º
                    if response.source_nodes:
                        with st.expander("å‚ç…§ã•ã‚ŒãŸã‚½ãƒ¼ã‚¹ã‚’ç¢ºèª"):
                            for i, node in enumerate(response.source_nodes):
                                st.markdown(f"--- **ã‚½ãƒ¼ã‚¹ {i+1} (é–¢é€£åº¦: {node.score:.2f})** ---")
                                st.text_area(
                                    label=f"ã‚½ãƒ¼ã‚¹ {i+1} ã®å†…å®¹",
                                    value=node.text, 
                                    height=150, 
                                    disabled=True,
                                    key=f"chunk_{i}"
                                )
    else:
        st.error(
            "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸãŸã‚ã€QAã‚·ã‚¹ãƒ†ãƒ ã‚’èµ·å‹•ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
            "ãƒšãƒ¼ã‚¸ä¸Šéƒ¨ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèªã—ã€**è¨­å®šã‚„GCSã®çŠ¶æ…‹ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„**ã€‚ç‰¹ã«ã€`secrets.toml`ã®ã‚­ãƒ¼ã¨å€¤ãŒæ­£ã—ã„ã‹å†ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        )

if __name__ == "__main__":
    main()
